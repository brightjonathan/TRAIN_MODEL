{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Read the file"
      ],
      "metadata": {
        "id": "TwmJ6LHfh9aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/TRAIN_MODEL/data/DummyData.txt\"\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "len(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqWubYCeiRYu",
        "outputId": "940b96db-888d-4c54-97d5-f0405919beba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the conversation(By filtering)"
      ],
      "metadata": {
        "id": "0E-dx_kPitHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "encryption_message = \"Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.\"\n",
        "media_pattern = \"<Media omitted>\"\n",
        "email_pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}'\n",
        "url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "edited_message = \"<This message was edited>\"\n",
        "deleted_message = \"You deleted this message\"\n",
        "null_message = \"null\"\n",
        "created_group_message = \"created group\"\n",
        "added_you_to_group_message = \"added you\"\n",
        "tagging_pattern = r'@[\\w]+'\n",
        "\n",
        "\n",
        "filtered_lines = []\n",
        "for line in lines:\n",
        "    if (\n",
        "            encryption_message not in line and\n",
        "            deleted_message not in line and\n",
        "            null_message != line.split(\" \")[-1] and\n",
        "            media_pattern not in line and\n",
        "            created_group_message not in line and\n",
        "            added_you_to_group_message not in line and\n",
        "            not re.search(email_pattern, line) and\n",
        "            not re.search(url_pattern, line)\n",
        "    ):\n",
        "        line = line.replace(edited_message, \"\").strip()\n",
        "        line = re.sub(tagging_pattern, \"\", line).strip()\n",
        "        filtered_lines.append(line)\n",
        "\n",
        "pattern = r'(\\d{2}/\\d{2}/\\d{4}, \\d{2}:\\d{2}) - (.*?): (.*?)(?=\\n\\d{2}/\\d{2}/\\d{4}, \\d{2}:\\d{2} -|$)'\n",
        "content = '\\n'.join(filtered_lines)\n",
        "messages = re.findall(pattern, content, re.DOTALL)\n",
        "\n",
        "lines_removed = len(lines) - len(filtered_lines)\n",
        "print(f\"Lines removed: {lines_removed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti4ba1xHiqDL",
        "outputId": "18dd3ef9-b6c4-436a-f927-59ee623d66bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create the dataset\n",
        "\n",
        "1. Group messages by\n",
        "\n",
        "If a conversation is structured as follows:\n",
        "\n",
        "User 1: Hey!  \n",
        "User 1: How are you?  \n",
        "User 2: I am fine  \n",
        "User 2: And you?  \n",
        "User 1: Good.  \n",
        "We want to transform it into:\n",
        "\n",
        "User 1: Hey!\\nHow are you?\n",
        "User 2: I am fine\\nAnd you?  \n",
        "User 1: Good  "
      ],
      "metadata": {
        "id": "w1zNqNkojwra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_messages = []\n",
        "\n",
        "for _, sender, message in messages:\n",
        "    if grouped_messages and grouped_messages[-1][\"sender\"] == sender:\n",
        "        grouped_messages[-1][\"message\"] += \"\\n\" + message\n",
        "    else:\n",
        "        grouped_messages.append({\n",
        "            \"sender\": sender,\n",
        "            \"message\": message\n",
        "        })\n",
        "\n",
        "len(grouped_messages)\n",
        "\n",
        "#this code transforms a sequential list of individual messages into a list\n",
        "#where consecutive messages from the same person are combined into a single entry,\n",
        "#effectively grouping the conversation by turns from each participant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i7V22r5j572",
        "outputId": "4f1ba293-fe5e-40e0-899f-15a2fa2c1644"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Include special tokens\n",
        "\n",
        "Each message follows this format:\n",
        "\n",
        "<|startoftext|>Sender<|separator|>Message<|endoftext|>"
      ],
      "metadata": {
        "id": "0ioQCzYOlO_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define special tokens\n",
        "start_of_text_token = \"<|startoftext|>\"\n",
        "end_of_text_token = \"<|endoftext|>\"\n",
        "separator_token = \"<|separator|>\"\n",
        "\n",
        "fine_tuning_data = []\n",
        "\n",
        "for message in grouped_messages:\n",
        "    sender = message[\"sender\"]\n",
        "    message_text = message[\"message\"]\n",
        "    input_sequence = f\"{start_of_text_token}{sender}{separator_token}{message_text}{end_of_text_token}\"\n",
        "    fine_tuning_data.append(input_sequence)\n",
        "\n",
        "len(fine_tuning_data)\n",
        "\n",
        "\n",
        "#This code is to structure the conversation data into a format suitable for training or fine-tuning a language model,\n",
        "#where the special tokens help the model understand the different components of each conversation turn."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta-V57PClYjU",
        "outputId": "d846312d-cf58-4736-824d-91495cc7ab9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the fine tune data in the path\n",
        "import json  #imported JSON FORMAT\n",
        "\n",
        "save_path = \"/content/TRAIN_MODEL/data/fine_tuning.json\"\n",
        "with open(save_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(fine_tuning_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "RarniVkin4t1"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}