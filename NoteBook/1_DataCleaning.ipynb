{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the files and applying filters to the data\n",
        ""
      ],
      "metadata": {
        "id": "CGMg5-1qVjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Remove lines containing a WhatsApp encryption notice\n",
        "2. Remove lines with <Media omitted>\n",
        "3. Remove lines containing email addresses.\n",
        "4. Remove lines containing links\n",
        "5. Replace <This message was edited> with an empty string.\n",
        "6. Remove lines with the text You deleted this message\n",
        "7. Remove lines with the text null\n",
        "8. Remove lines with the text created group\n",
        "9. Remove lines with the text added you\n",
        "10. Replace tagging (@person) with an empty string\n",
        "\n",
        "After filtering, we normalize the content:\n",
        "\n",
        "1. Replace narrow no-break spaces (\\u202F) with a regular space (\" \") â€” often found in iOS exports.\n",
        "2. Strip invisible Unicode characters like \\u200E (Left-to-Right Mark) and \\u200F (Right-to-Left Mark).\n"
      ],
      "metadata": {
        "id": "o9kAmSeDVxqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YFWKHgfXVxpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_whatsapp_chat(file_path: str) -> pd.DataFrame:\n",
        "    # Define filtering patterns\n",
        "    encryption_message = \"Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.\"\n",
        "    media_pattern = \"<Media omitted>\"\n",
        "    email_pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}'\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    edited_message = \"<This message was edited>\"\n",
        "    deleted_message = \"You deleted this message\"\n",
        "    null_message = \"null\"\n",
        "    created_group_message = \"created group\"\n",
        "    added_you_to_group_message = \"added you\"\n",
        "    tagging_pattern = r'@[\\w]+'\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Apply filters to remove unwanted lines\n",
        "    filtered_lines = []\n",
        "    for line in lines:\n",
        "        if (\n",
        "            encryption_message not in line and\n",
        "            deleted_message not in line and\n",
        "            null_message != line.split(\" \")[-1] and\n",
        "            media_pattern not in line and\n",
        "            created_group_message not in line and\n",
        "            added_you_to_group_message not in line and\n",
        "            not re.search(email_pattern, line) and\n",
        "            not re.search(url_pattern, line)\n",
        "        ):\n",
        "            line = line.replace(edited_message, \"\").strip()\n",
        "            line = re.sub(tagging_pattern, \"\", line).strip()\n",
        "            filtered_lines.append(line)\n",
        "\n",
        "    # Normalize content:\n",
        "    content = '\\n'.join(filtered_lines)\n",
        "    # Replace narrow no-break space (iOS specific)\n",
        "    content = content.replace('\\u202f', ' ')\n",
        "    # Remove square brackets if they surround the timestamp (only for iOS)\n",
        "    content = re.sub(\n",
        "        r'\\[(\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2}(?::\\d{2})?\\s?[APap][Mm])\\]',\n",
        "        r'\\1',\n",
        "        content\n",
        "    )\n",
        "    # Remove LRM and RLM characters (Left-to-Right Mark and Right-to-Left Mark)\n",
        "    content = content.replace('\\u200E', '').replace('\\u200F', '')\n",
        "\n",
        "    # Updated regex pattern to match both iOS and Android WhatsApp exports.\n",
        "    pattern = r'(\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2}(?::\\d{2})?(?:\\s?[APap][Mm])?)\\s?(?:-|\\~)?\\s?(.*?): (.*?)(?=\\n\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2}|$)'\n",
        "    messages = re.findall(pattern, content, re.DOTALL)\n",
        "    df = pd.DataFrame(messages, columns=['timestamp', 'sender', 'message'])\n",
        "\n",
        "    timestamps = []\n",
        "    for timestamp in df['timestamp']:\n",
        "        try:\n",
        "            timestamp = pd.to_datetime(\n",
        "                timestamp, format='mixed', errors='coerce')\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing timestamp '{timestamp}': {e}\")\n",
        "            timestamp = pd.NaT\n",
        "        timestamps.append(timestamp)\n",
        "\n",
        "    df['timestamp'] = timestamps\n",
        "    return df"
      ],
      "metadata": {
        "id": "bdQINE4vWpvK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The all_chats dictionary holds the content of each file as a dataframe with three columns: timestamp, sender, and message.\n",
        "from pathlib import Path\n",
        "\n",
        "all_chats = {}\n",
        "data_directory = Path(\"/content/TRAIN_MODEL/DATA\")\n",
        "for file in data_directory.glob('*.txt'):\n",
        "    file_name = file.stem\n",
        "    all_chats[file_name] = read_whatsapp_chat(file)"
      ],
      "metadata": {
        "id": "RkcJ6Ou4XBkX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text sequence\n",
        "\n",
        "The text should be merged into a single sequence to prepare it for the next step, where the BPE algorithm will be applied and the text will be encoded.\n"
      ],
      "metadata": {
        "id": "VKQZIaKHXoTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sequence = \"\"\n",
        "for file_name in all_chats.keys():\n",
        "    text_sequence += \" \".join(all_chats[file_name]['message'].values)\n",
        "\n",
        "len(text_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFcGuWVBXvT4",
        "outputId": "625ff233-5030-425c-8044-79a310ed35e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1930710"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TRAIN_MODEL/output/combined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_sequence)"
      ],
      "metadata": {
        "id": "eQ6kn8KKYVAh"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}